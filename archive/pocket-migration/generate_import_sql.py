#!/usr/bin/env python3
"""
Generate SQL INSERT statements for importing Pocket links to PSReadThis.
This can be run directly in the Supabase SQL Editor to bypass RLS issues.
"""

import csv
import uuid
from datetime import datetime

USER_ID = "3ad801b9-b41d-4cca-a5ba-2065a1d6ce97"

def unix_to_iso(unix_timestamp: str) -> str:
    """Convert Unix timestamp to ISO format for PostgreSQL."""
    try:
        if unix_timestamp and unix_timestamp.isdigit():
            dt = datetime.fromtimestamp(int(unix_timestamp))
            return dt.isoformat() + "+00:00"
    except (ValueError, OSError):
        pass
    return datetime.now().isoformat() + "+00:00"

def escape_sql_string(value: str) -> str:
    """Escape string for SQL by replacing single quotes."""
    if value is None:
        return "NULL"
    return "'" + value.replace("'", "''") + "'"

def generate_sql_inserts(csv_filename: str = "pocket_unread_links.csv"):
    """Generate SQL INSERT statements for all unread links."""
    
    print("üîÑ Generating SQL INSERT statements...")
    print("=" * 60)
    
    sql_statements = []
    processed_count = 0
    
    # Header comment
    sql_statements.append("-- PSReadThis Import: Pocket Unread Links")
    sql_statements.append("-- Generated by generate_import_sql.py")
    sql_statements.append(f"-- Import Date: {datetime.now().isoformat()}")
    sql_statements.append("-- Total Links: TBD")
    sql_statements.append("")
    sql_statements.append("-- Disable triggers temporarily to avoid HTTP requests during bulk insert")
    sql_statements.append("ALTER TABLE links DISABLE TRIGGER trg_fetch_metadata;")
    sql_statements.append("")
    
    try:
        with open(csv_filename, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            
            for row in reader:
                if row['status'] == 'unread':
                    # Generate UUID for this link
                    link_id = str(uuid.uuid4())
                    
                    # Convert timestamp
                    created_at = unix_to_iso(row['time_added'])
                    
                    # Prepare values (escape strings properly)
                    values = {
                        'id': escape_sql_string(link_id),
                        'user_id': escape_sql_string(USER_ID),
                        'raw_url': escape_sql_string(row['url']),
                        'resolved_url': 'NULL',
                        'title': escape_sql_string(row['title']) if row['title'] else 'NULL',
                        'list': escape_sql_string('read'),
                        'status': escape_sql_string('unread'),
                        'device_saved': escape_sql_string('pocket_import'),
                        'created_at': escape_sql_string(created_at)
                    }
                    
                    # Create INSERT statement
                    sql = f"""INSERT INTO links (id, user_id, raw_url, resolved_url, title, list, status, device_saved, created_at) 
VALUES ({values['id']}, {values['user_id']}, {values['raw_url']}, {values['resolved_url']}, {values['title']}, {values['list']}, {values['status']}, {values['device_saved']}, {values['created_at']});"""
                    
                    sql_statements.append(sql)
                    processed_count += 1
                    
                    # Add progress comments every 50 links
                    if processed_count % 50 == 0:
                        sql_statements.append(f"-- Progress: {processed_count} links processed")
                        sql_statements.append("")
    
    except Exception as e:
        print(f"‚ùå Error reading CSV: {e}")
        return
    
    # Footer
    sql_statements.append("")
    sql_statements.append("-- Re-enable triggers")
    sql_statements.append("ALTER TABLE links ENABLE TRIGGER trg_fetch_metadata;")
    sql_statements.append("")
    sql_statements.append(f"-- Import complete: {processed_count} links added")
    sql_statements.append("-- Run the following to update metadata for imported links:")
    sql_statements.append("-- UPDATE links SET title = title WHERE device_saved = 'pocket_import' AND title IS NULL;")
    
    # Update header with actual count
    sql_statements[3] = f"-- Total Links: {processed_count}"
    
    # Write to file
    output_file = "import_pocket_links.sql"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(sql_statements))
    
    print(f"‚úÖ Generated SQL file: {output_file}")
    print(f"üìä Total links: {processed_count}")
    print(f"üìÑ Total SQL statements: {processed_count + 4}")  # +4 for the trigger commands
    
    # Show sample statements
    print("\nüîç Sample SQL statements:")
    print("-" * 60)
    sample_statements = [stmt for stmt in sql_statements if stmt.startswith('INSERT')][:3]
    for i, stmt in enumerate(sample_statements, 1):
        print(f"{i}. {stmt[:100]}...")
    
    print(f"\nüìã Instructions:")
    print("1. Open your Supabase SQL Editor")
    print(f"2. Copy and paste the contents of '{output_file}'")
    print("3. Execute the SQL script")
    print("4. Check your PSReadThis app - links should appear!")
    
    print(f"\n‚ö†Ô∏è  Note: Triggers are disabled during import for performance")
    print("   Metadata (titles/descriptions) will be fetched when you view links")

if __name__ == "__main__":
    generate_sql_inserts() 