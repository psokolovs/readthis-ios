#!/usr/bin/env python3
"""
Generate SQL INSERT statements for importing Pocket links to PSReadThis.
This version handles duplicates safely using ON CONFLICT DO NOTHING.
"""

import csv
import uuid
from datetime import datetime

USER_ID = "3ad801b9-b41d-4cca-a5ba-2065a1d6ce97"

def unix_to_iso(unix_timestamp: str) -> str:
    """Convert Unix timestamp to ISO format for PostgreSQL."""
    try:
        if unix_timestamp and unix_timestamp.isdigit():
            dt = datetime.fromtimestamp(int(unix_timestamp))
            return dt.isoformat() + "+00:00"
    except (ValueError, OSError):
        pass
    return datetime.now().isoformat() + "+00:00"

def escape_sql_string(value: str) -> str:
    """Escape string for SQL by replacing single quotes."""
    if value is None:
        return "NULL"
    return "'" + value.replace("'", "''") + "'"

def generate_sql_inserts_safe(csv_filename: str = "pocket_unread_links.csv"):
    """Generate SQL INSERT statements that safely handle duplicates."""
    
    print("üîÑ Generating SAFE SQL INSERT statements...")
    print("=" * 60)
    
    sql_statements = []
    processed_count = 0
    
    # Header comment
    sql_statements.append("-- PSReadThis Import: Pocket Unread Links (SAFE VERSION)")
    sql_statements.append("-- Generated by generate_import_sql_safe.py")
    sql_statements.append(f"-- Import Date: {datetime.now().isoformat()}")
    sql_statements.append("-- Total Links: TBD")
    sql_statements.append("-- This version safely handles duplicate URLs")
    sql_statements.append("")
    sql_statements.append("-- Disable triggers temporarily to avoid HTTP requests during bulk insert")
    sql_statements.append("ALTER TABLE links DISABLE TRIGGER trg_fetch_metadata;")
    sql_statements.append("")
    
    try:
        with open(csv_filename, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            
            for row in reader:
                if row['status'] == 'unread':
                    # Generate UUID for this link
                    link_id = str(uuid.uuid4())
                    
                    # Convert timestamp
                    created_at = unix_to_iso(row['time_added'])
                    
                    # Prepare values (escape strings properly)
                    values = {
                        'id': escape_sql_string(link_id),
                        'user_id': escape_sql_string(USER_ID),
                        'raw_url': escape_sql_string(row['url']),
                        'resolved_url': 'NULL',
                        'title': escape_sql_string(row['title']) if row['title'] else 'NULL',
                        'list': escape_sql_string('read'),
                        'status': escape_sql_string('unread'),
                        'device_saved': escape_sql_string('pocket_import'),
                        'created_at': escape_sql_string(created_at)
                    }
                    
                    # Create INSERT statement with ON CONFLICT DO NOTHING
                    sql = f"""INSERT INTO links (id, user_id, raw_url, resolved_url, title, list, status, device_saved, created_at) 
VALUES ({values['id']}, {values['user_id']}, {values['raw_url']}, {values['resolved_url']}, {values['title']}, {values['list']}, {values['status']}, {values['device_saved']}, {values['created_at']})
ON CONFLICT (user_id, raw_url) DO NOTHING;"""
                    
                    sql_statements.append(sql)
                    processed_count += 1
                    
                    # Add progress comments every 50 links
                    if processed_count % 50 == 0:
                        sql_statements.append(f"-- Progress: {processed_count} links processed")
                        sql_statements.append("")
    
    except Exception as e:
        print(f"‚ùå Error reading CSV: {e}")
        return
    
    # Footer
    sql_statements.append("")
    sql_statements.append("-- Re-enable triggers")
    sql_statements.append("ALTER TABLE links ENABLE TRIGGER trg_fetch_metadata;")
    sql_statements.append("")
    sql_statements.append(f"-- Import attempted for {processed_count} links")
    sql_statements.append("-- Duplicates were safely skipped")
    sql_statements.append("")
    sql_statements.append("-- Check how many were actually inserted:")
    sql_statements.append("SELECT COUNT(*) as imported_links FROM links WHERE device_saved = 'pocket_import';")
    sql_statements.append("")
    sql_statements.append("-- Check total unread links:")
    sql_statements.append("SELECT COUNT(*) as total_unread FROM links WHERE status = 'unread';")
    
    # Update header with actual count
    sql_statements[3] = f"-- Total Links: {processed_count}"
    
    # Write to file
    output_file = "import_pocket_links_safe.sql"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(sql_statements))
    
    print(f"‚úÖ Generated SAFE SQL file: {output_file}")
    print(f"üìä Total links: {processed_count}")
    print(f"üìÑ Total SQL statements: {processed_count + 6}")  # +6 for the commands
    
    # Show sample statements
    print("\nüîç Sample SQL statements:")
    print("-" * 60)
    sample_statements = [stmt for stmt in sql_statements if stmt.startswith('INSERT')][:2]
    for i, stmt in enumerate(sample_statements, 1):
        lines = stmt.split('\n')
        print(f"{i}. {lines[0][:80]}...")
        print(f"   {lines[2]}")  # Show the ON CONFLICT line
    
    print(f"\nüìã Instructions:")
    print("1. Open your Supabase SQL Editor")
    print(f"2. Copy and paste the contents of '{output_file}'")
    print("3. Execute the SQL script")
    print("4. Check the final SELECT statements to see how many were imported")
    print("5. Open your PSReadThis app to see the new links!")
    
    print(f"\n‚úÖ Benefits of this version:")
    print("   - Safely skips duplicate URLs (no errors)")
    print("   - Shows count of actually imported links")
    print("   - Preserves existing data")

if __name__ == "__main__":
    generate_sql_inserts_safe() 